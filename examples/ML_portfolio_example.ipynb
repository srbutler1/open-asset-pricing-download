{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88102421-a112-4104-a500-9994fed738d2",
   "metadata": {},
   "source": [
    "# Machine Learning Portfolio Example\n",
    "\n",
    "This example illustrates how to use all Chen-Zimmermann predictors, together with CRSP data. We'll use the `openassetpricing` package to download the Chen-Zimmermann predictors, merge with monthly CRSP, fit returns to lagged signals, and form portfolios in out-of-sample tests. Specifically, we'll use a \"groovy\" model (fit on the 1960s and 1970s) to try to predict returns during hair metal (1980s), gangsta rap (1990s), emo (2000s), and other more recent samples. Does the groovy model work even in the TSwift (and that Chiefs guy) era?\n",
    "\n",
    "Downloading all of the signals takes some time and requires substantial RAM. It also requires a WRDS account, since some predictors require data from WRDS (size, short-term reversal, price). \n",
    "\n",
    "To manage memory, we'll use Polars dataframes instead of Pandas, and set signal variables to float32 (instead of float64). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a4767164-0056-4cb3-a1c2-b1c3c7289b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import openassetpricing as oap\n",
    "import numpy as np\n",
    "import wrds\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize OpenAP\n",
    "openap = oap.OpenAP()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a571ef",
   "metadata": {},
   "source": [
    "<span style=\"color:orange;font-weight:bold\">Optional:</span>\n",
    "By default, we'll use all 212 signals for forming portfolios. This takes about 35 minutes on a desktop with with 64 GB of RAM. \n",
    "\n",
    "You may want to reduce `nsignals_for_ml` for a faster run or a smaller machine. We found `nsignals_for_ml = 20` runs quickly on a laptop with 16 GB of RAM. But it won't reproduce the nice results in [Gu, Kelly, Xiu (2020)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3159577); [Chen and McCoy (2024)](https://arxiv.org/abs/2207.13071); and elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bc9b3c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-specified number of signals for ML\n",
    "nsignals_for_ml = 212"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7d07ff-4ec0-496b-9883-0a5ed96260c1",
   "metadata": {},
   "source": [
    "# Download data\n",
    "\n",
    "You'll have to enter your WRDS credentials twice: once to download the CRSP returns, and once to download all Chen-Zimmermann predictors (including size, short-term reversal, and price). The downloads take a couple minutes in total. We keep only standard common stocks on major exchanges (see https://github.com/OpenSourceAP/CrossSection/issues/133)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d61e0753-c465-4cb3-8440-7fdf95d4e21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRDS recommends setting up a .pgpass file.\n",
      "You can create this file yourself at any time with the create_pgpass_file() function.\n",
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "wrds_conn = wrds.Connection()\n",
    "\n",
    "crsp = wrds_conn.raw_sql(\n",
    "    \"\"\"select a.permno, a.date, a.ret*100 as ret\n",
    "                        from crsp.msf a\n",
    "                        join crsp.msenames b \n",
    "                        on a.permno = b.permno\n",
    "                        and a.date >= b.namedt\n",
    "                        and a.date <= b.nameendt\n",
    "                        where b.shrcd in (10, 11, 12) \n",
    "                        and b.exchcd in (1, 2, 3)\"\"\",\n",
    "    date_cols=[\"date\"],\n",
    ")\n",
    "\n",
    "crsp = pl.from_pandas(crsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b3b1acb9-e7bc-441a-9e98-802be91e10d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRDS recommends setting up a .pgpass file.\n",
      "You can create this file yourself at any time with the create_pgpass_file() function.\n",
      "Loading library list...\n",
      "Done\n",
      "\n",
      "Data is downloaded: 2 mins\n"
     ]
    }
   ],
   "source": [
    "# Download all Chen-Zimmermann predictors\n",
    "bigdat = openap.dl_all_signals(\"polars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "90776261-5522-4485-864f-6cd4e63e6b87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (24, 214)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>permno</th><th>yyyymm</th><th>AM</th><th>AOP</th><th>AbnormalAccruals</th><th>Accruals</th><th>AccrualsBM</th><th>Activism1</th><th>Activism2</th><th>AdExp</th><th>AgeIPO</th><th>AnalystRevision</th><th>AnalystValue</th><th>AnnouncementReturn</th><th>AssetGrowth</th><th>BM</th><th>BMdec</th><th>BPEBM</th><th>Beta</th><th>BetaFP</th><th>BetaLiquidityPS</th><th>BetaTailRisk</th><th>BidAskSpread</th><th>BookLeverage</th><th>BrandInvest</th><th>CBOperProf</th><th>CF</th><th>CPVolSpread</th><th>Cash</th><th>CashProd</th><th>ChAssetTurnover</th><th>ChEQ</th><th>ChForecastAccrual</th><th>ChInv</th><th>ChInvIA</th><th>ChNAnalyst</th><th>ChNNCOA</th><th>&hellip;</th><th>Spinoff</th><th>SurpriseRD</th><th>Tax</th><th>TotalAccruals</th><th>TrendFactor</th><th>UpRecomm</th><th>VarCF</th><th>VolMkt</th><th>VolSD</th><th>VolumeTrend</th><th>XFIN</th><th>betaVIX</th><th>cfp</th><th>dCPVolSpread</th><th>dNoa</th><th>dVolCall</th><th>dVolPut</th><th>fgr5yrLag</th><th>grcapx</th><th>grcapx3y</th><th>hire</th><th>iomom_cust</th><th>iomom_supp</th><th>realestate</th><th>retConglomerate</th><th>roaq</th><th>sfe</th><th>sinAlgo</th><th>skew1</th><th>std_turn</th><th>tang</th><th>zerotrade12M</th><th>zerotrade1M</th><th>zerotrade6M</th><th>Price</th><th>Size</th><th>STreversal</th></tr><tr><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>&hellip;</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>10107</td><td>198603</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>0.242157</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-3.314186</td><td>-6.553609</td><td>-0.0</td></tr><tr><td>10107</td><td>198604</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.004334</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>0.193979</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.015511</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.4361e-8</td><td>null</td><td>-3.473518</td><td>-6.712941</td><td>-0.172727</td></tr><tr><td>10107</td><td>198605</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.004821</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>0.159634</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.013768</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2.6631e-8</td><td>null</td><td>-3.54818</td><td>-6.787603</td><td>-0.077519</td></tr><tr><td>10107</td><td>198606</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>11.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.007609</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>0.1693</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.017796</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>5.4195e-8</td><td>null</td><td>-3.42589</td><td>-6.665352</td><td>0.115108</td></tr><tr><td>10107</td><td>198607</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>11.0</td><td>null</td><td>null</td><td>0.036261</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.006991</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>0.152681</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.003951</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>5.1931e-8</td><td>null</td><td>-3.349904</td><td>-6.589366</td><td>0.073171</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>10107</td><td>198710</td><td>0.064755</td><td>-2.042913</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.005479</td><td>12.0</td><td>0.509589</td><td>0.547472</td><td>-0.09505</td><td>null</td><td>-1.728493</td><td>null</td><td>0.034875</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.014662</td><td>-1.225411</td><td>null</td><td>0.309139</td><td>0.017049</td><td>null</td><td>0.442655</td><td>-24.01692</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>1.0</td><td>null</td><td>1.971073</td><td>null</td><td>0.286837</td><td>null</td><td>null</td><td>-0.231705</td><td>null</td><td>null</td><td>-0.282056</td><td>-0.000679</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-18.17</td><td>null</td><td>null</td><td>0.0</td><td>-22.978674</td><td>-24.611324</td><td>-0.041296</td><td>null</td><td>0.066585</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>3.3413e-8</td><td>1.0079e-8</td><td>5.9255e-8</td><td>-3.907011</td><td>-7.877284</td><td>0.249057</td></tr><tr><td>10107</td><td>198711</td><td>0.07199</td><td>-2.042913</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.006091</td><td>12.0</td><td>1.016129</td><td>0.547472</td><td>-0.09505</td><td>null</td><td>-1.728493</td><td>null</td><td>0.038372</td><td>1.5192</td><td>null</td><td>null</td><td>null</td><td>0.012299</td><td>-1.225411</td><td>null</td><td>0.309139</td><td>0.018954</td><td>null</td><td>0.442655</td><td>-21.436035</td><td>null</td><td>null</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>1.0</td><td>null</td><td>1.971073</td><td>null</td><td>0.327159</td><td>null</td><td>null</td><td>-0.268145</td><td>null</td><td>null</td><td>-0.282056</td><td>0.000342</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-18.17</td><td>null</td><td>null</td><td>0.0</td><td>-2.592174</td><td>-5.820603</td><td>-0.039997</td><td>null</td><td>0.066585</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>3.0609e-8</td><td>4.2201e-9</td><td>5.2281e-8</td><td>-3.801091</td><td>-7.771365</td><td>0.100503</td></tr><tr><td>10107</td><td>198712</td><td>0.09963</td><td>-2.042913</td><td>-0.07659</td><td>-0.045392</td><td>null</td><td>null</td><td>null</td><td>0.009927</td><td>12.0</td><td>1.0</td><td>0.547472</td><td>-0.09505</td><td>-0.685344</td><td>-2.411766</td><td>0.190642</td><td>0.038139</td><td>1.543116</td><td>null</td><td>null</td><td>null</td><td>0.011936</td><td>-1.203463</td><td>null</td><td>0.495858</td><td>0.027521</td><td>null</td><td>0.442655</td><td>-19.628498</td><td>null</td><td>-1.716081</td><td>null</td><td>-0.037283</td><td>-2.403085</td><td>null</td><td>-0.1553</td><td>&hellip;</td><td>1.0</td><td>1.0</td><td>1.622298</td><td>-0.339823</td><td>0.385367</td><td>null</td><td>null</td><td>-0.235936</td><td>null</td><td>null</td><td>-0.088756</td><td>0.001031</td><td>0.016015</td><td>null</td><td>-0.440807</td><td>null</td><td>null</td><td>-18.17</td><td>null</td><td>null</td><td>-0.446615</td><td>25.128487</td><td>11.876118</td><td>-0.03439</td><td>null</td><td>0.073879</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2.9871e-8</td><td>1.0745e-8</td><td>5.5116e-8</td><td>-3.993603</td><td>-7.968394</td><td>-0.21229</td></tr><tr><td>10107</td><td>198801</td><td>0.09695</td><td>-2.042913</td><td>-0.07659</td><td>-0.045392</td><td>null</td><td>null</td><td>null</td><td>0.00966</td><td>13.0</td><td>1.021164</td><td>0.547472</td><td>-0.018308</td><td>-0.685344</td><td>-2.411766</td><td>null</td><td>0.037245</td><td>1.422204</td><td>null</td><td>null</td><td>null</td><td>0.017505</td><td>-1.203463</td><td>null</td><td>0.495858</td><td>0.026781</td><td>null</td><td>0.443408</td><td>-20.231276</td><td>null</td><td>-1.716081</td><td>1.0</td><td>-0.037283</td><td>-2.407764</td><td>null</td><td>-0.1553</td><td>&hellip;</td><td>1.0</td><td>1.0</td><td>1.908585</td><td>-0.339823</td><td>0.407496</td><td>null</td><td>null</td><td>-0.237013</td><td>null</td><td>null</td><td>-0.088756</td><td>0.002181</td><td>0.015584</td><td>null</td><td>-0.440807</td><td>null</td><td>null</td><td>-18.17</td><td>null</td><td>null</td><td>-0.446615</td><td>-3.299253</td><td>1.857615</td><td>-0.036876</td><td>null</td><td>0.073879</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2.8602e-8</td><td>8.5760e-9</td><td>5.5054e-8</td><td>-4.020877</td><td>-7.995668</td><td>-0.02765</td></tr><tr><td>10107</td><td>198802</td><td>0.091031</td><td>-2.042913</td><td>-0.07659</td><td>-0.045392</td><td>null</td><td>null</td><td>null</td><td>0.00907</td><td>13.0</td><td>1.067358</td><td>0.547472</td><td>-0.018308</td><td>-0.685344</td><td>-2.411766</td><td>null</td><td>0.035245</td><td>1.374193</td><td>null</td><td>null</td><td>null</td><td>0.006433</td><td>-1.203463</td><td>null</td><td>0.495858</td><td>0.025146</td><td>null</td><td>0.443408</td><td>-21.68799</td><td>null</td><td>-1.716081</td><td>1.0</td><td>-0.037283</td><td>-2.18095</td><td>null</td><td>-0.1553</td><td>&hellip;</td><td>1.0</td><td>1.0</td><td>1.908585</td><td>-0.339823</td><td>0.382793</td><td>null</td><td>null</td><td>-0.225421</td><td>-5.325614</td><td>null</td><td>-0.088756</td><td>0.00237</td><td>0.014632</td><td>null</td><td>-0.440807</td><td>null</td><td>null</td><td>-18.17</td><td>null</td><td>null</td><td>-0.446615</td><td>7.998837</td><td>8.833039</td><td>-0.038497</td><td>null</td><td>0.073879</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2.8764e-8</td><td>8.5019e-9</td><td>5.5391e-8</td><td>-4.083873</td><td>-8.058664</td><td>-0.065022</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (24, 214)\n",
       "┌────────┬────────┬──────────┬───────────┬───┬─────────────┬───────────┬───────────┬────────────┐\n",
       "│ permno ┆ yyyymm ┆ AM       ┆ AOP       ┆ … ┆ zerotrade6M ┆ Price     ┆ Size      ┆ STreversal │\n",
       "│ ---    ┆ ---    ┆ ---      ┆ ---       ┆   ┆ ---         ┆ ---       ┆ ---       ┆ ---        │\n",
       "│ i32    ┆ i32    ┆ f32      ┆ f32       ┆   ┆ f32         ┆ f32       ┆ f32       ┆ f32        │\n",
       "╞════════╪════════╪══════════╪═══════════╪═══╪═════════════╪═══════════╪═══════════╪════════════╡\n",
       "│ 10107  ┆ 198603 ┆ null     ┆ null      ┆ … ┆ null        ┆ -3.314186 ┆ -6.553609 ┆ -0.0       │\n",
       "│ 10107  ┆ 198604 ┆ null     ┆ null      ┆ … ┆ null        ┆ -3.473518 ┆ -6.712941 ┆ -0.172727  │\n",
       "│ 10107  ┆ 198605 ┆ null     ┆ null      ┆ … ┆ null        ┆ -3.54818  ┆ -6.787603 ┆ -0.077519  │\n",
       "│ 10107  ┆ 198606 ┆ null     ┆ null      ┆ … ┆ null        ┆ -3.42589  ┆ -6.665352 ┆ 0.115108   │\n",
       "│ 10107  ┆ 198607 ┆ null     ┆ null      ┆ … ┆ null        ┆ -3.349904 ┆ -6.589366 ┆ 0.073171   │\n",
       "│ …      ┆ …      ┆ …        ┆ …         ┆ … ┆ …           ┆ …         ┆ …         ┆ …          │\n",
       "│ 10107  ┆ 198710 ┆ 0.064755 ┆ -2.042913 ┆ … ┆ 5.9255e-8   ┆ -3.907011 ┆ -7.877284 ┆ 0.249057   │\n",
       "│ 10107  ┆ 198711 ┆ 0.07199  ┆ -2.042913 ┆ … ┆ 5.2281e-8   ┆ -3.801091 ┆ -7.771365 ┆ 0.100503   │\n",
       "│ 10107  ┆ 198712 ┆ 0.09963  ┆ -2.042913 ┆ … ┆ 5.5116e-8   ┆ -3.993603 ┆ -7.968394 ┆ -0.21229   │\n",
       "│ 10107  ┆ 198801 ┆ 0.09695  ┆ -2.042913 ┆ … ┆ 5.5054e-8   ┆ -4.020877 ┆ -7.995668 ┆ -0.02765   │\n",
       "│ 10107  ┆ 198802 ┆ 0.091031 ┆ -2.042913 ┆ … ┆ 5.5391e-8   ┆ -4.083873 ┆ -8.058664 ┆ -0.065022  │\n",
       "└────────┴────────┴──────────┴───────────┴───┴─────────────┴───────────┴───────────┴────────────┘"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get names of all signals\n",
    "signal_list = [col for col in bigdat.columns if col not in [\"permno\", \"yyyymm\"]]\n",
    "\n",
    "bigdat = bigdat.with_columns(pl.col(signal_list).cast(pl.Float32))\n",
    "\n",
    "# show MSFT (permno = 10107)\n",
    "bigdat.filter(pl.col(\"permno\") == 10107).head(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18528cff",
   "metadata": {},
   "source": [
    "Above gives you a sense of what the data looks like. First two columns are identifiers. The other columns are the values of the signals. There are a lot of missing values for MSFT (permno = 10107) when it first listed, back in 1986. But by 1987, a lot of these values are filled in. This is a common missingness pattern for accounting predictors ([Chen and McCoy (2024)](https://arxiv.org/abs/2207.13071); also [these discussion slides](https://drive.google.com/file/d/1e8aGG9JtufQKeA_jMZ3XaP6wNhJS6Y0q/view))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bb1200-1b8c-4aab-809f-078fed8c4c9d",
   "metadata": {},
   "source": [
    "# Lag signals and merge\n",
    "\n",
    "To lag signals, you can just add one month to the `yyyymm` column. For simplicity, let's fill in the day of the new variable `date` as the 28th (the signals are assumed to be available for trading at the end of the month). You can keep around `yyyymm` as `yyyymm_signals` for sanity checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a39970f8-66ac-4518-b863-939800337670",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 215)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>permno</th><th>date</th><th>yyyymm_signals</th><th>AM</th><th>AOP</th><th>AbnormalAccruals</th><th>Accruals</th><th>AccrualsBM</th><th>Activism1</th><th>Activism2</th><th>AdExp</th><th>AgeIPO</th><th>AnalystRevision</th><th>AnalystValue</th><th>AnnouncementReturn</th><th>AssetGrowth</th><th>BM</th><th>BMdec</th><th>BPEBM</th><th>Beta</th><th>BetaFP</th><th>BetaLiquidityPS</th><th>BetaTailRisk</th><th>BidAskSpread</th><th>BookLeverage</th><th>BrandInvest</th><th>CBOperProf</th><th>CF</th><th>CPVolSpread</th><th>Cash</th><th>CashProd</th><th>ChAssetTurnover</th><th>ChEQ</th><th>ChForecastAccrual</th><th>ChInv</th><th>ChInvIA</th><th>ChNAnalyst</th><th>&hellip;</th><th>Spinoff</th><th>SurpriseRD</th><th>Tax</th><th>TotalAccruals</th><th>TrendFactor</th><th>UpRecomm</th><th>VarCF</th><th>VolMkt</th><th>VolSD</th><th>VolumeTrend</th><th>XFIN</th><th>betaVIX</th><th>cfp</th><th>dCPVolSpread</th><th>dNoa</th><th>dVolCall</th><th>dVolPut</th><th>fgr5yrLag</th><th>grcapx</th><th>grcapx3y</th><th>hire</th><th>iomom_cust</th><th>iomom_supp</th><th>realestate</th><th>retConglomerate</th><th>roaq</th><th>sfe</th><th>sinAlgo</th><th>skew1</th><th>std_turn</th><th>tang</th><th>zerotrade12M</th><th>zerotrade1M</th><th>zerotrade6M</th><th>Price</th><th>Size</th><th>STreversal</th></tr><tr><td>i32</td><td>date</td><td>i32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>&hellip;</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>10000</td><td>1986-02-28</td><td>198601</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.005234</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-1.475906</td><td>-2.778819</td><td>-0.0</td></tr><tr><td>10000</td><td>1986-03-28</td><td>198602</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.003488</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>4.7852e-8</td><td>null</td><td>-1.178655</td><td>-2.481568</td><td>0.257143</td></tr><tr><td>10000</td><td>1986-04-28</td><td>198603</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.002715</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.0234e-7</td><td>null</td><td>-1.490091</td><td>-2.793004</td><td>-0.365385</td></tr><tr><td>10000</td><td>1986-05-28</td><td>198604</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.000877</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>7.4675e-8</td><td>null</td><td>-1.386294</td><td>-2.719452</td><td>0.098592</td></tr><tr><td>10000</td><td>1986-06-28</td><td>198605</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.008817</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>7.6496e-8</td><td>null</td><td>-1.134423</td><td>-2.467581</td><td>0.222656</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 215)\n",
       "┌────────┬────────────┬──────────────┬──────┬───┬─────────────┬───────────┬───────────┬────────────┐\n",
       "│ permno ┆ date       ┆ yyyymm_signa ┆ AM   ┆ … ┆ zerotrade6M ┆ Price     ┆ Size      ┆ STreversal │\n",
       "│ ---    ┆ ---        ┆ ls           ┆ ---  ┆   ┆ ---         ┆ ---       ┆ ---       ┆ ---        │\n",
       "│ i32    ┆ date       ┆ ---          ┆ f32  ┆   ┆ f32         ┆ f32       ┆ f32       ┆ f32        │\n",
       "│        ┆            ┆ i32          ┆      ┆   ┆             ┆           ┆           ┆            │\n",
       "╞════════╪════════════╪══════════════╪══════╪═══╪═════════════╪═══════════╪═══════════╪════════════╡\n",
       "│ 10000  ┆ 1986-02-28 ┆ 198601       ┆ null ┆ … ┆ null        ┆ -1.475906 ┆ -2.778819 ┆ -0.0       │\n",
       "│ 10000  ┆ 1986-03-28 ┆ 198602       ┆ null ┆ … ┆ null        ┆ -1.178655 ┆ -2.481568 ┆ 0.257143   │\n",
       "│ 10000  ┆ 1986-04-28 ┆ 198603       ┆ null ┆ … ┆ null        ┆ -1.490091 ┆ -2.793004 ┆ -0.365385  │\n",
       "│ 10000  ┆ 1986-05-28 ┆ 198604       ┆ null ┆ … ┆ null        ┆ -1.386294 ┆ -2.719452 ┆ 0.098592   │\n",
       "│ 10000  ┆ 1986-06-28 ┆ 198605       ┆ null ┆ … ┆ null        ┆ -1.134423 ┆ -2.467581 ┆ 0.222656   │\n",
       "└────────┴────────────┴──────────────┴──────┴───┴─────────────┴───────────┴───────────┴────────────┘"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigdat = bigdat.select(\n",
    "    \"permno\",\n",
    "    # Create date that is one month ahead for merging with returns\n",
    "    pl.col(\"yyyymm\")\n",
    "    .cast(pl.String)\n",
    "    .add(\"28\")\n",
    "    .str.to_date(\"%Y%m%d\")\n",
    "    .dt.offset_by(\"1mo\")\n",
    "    .alias(\"date\"),\n",
    "    # rename yyyymm for clarity\n",
    "    pl.col(\"yyyymm\").alias(\"yyyymm_signals\"),\n",
    "    pl.col(signal_list),\n",
    ")\n",
    "\n",
    "bigdat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5151ecac-6c80-4b80-9c72-65a512890d3b",
   "metadata": {},
   "source": [
    "Now merge with CRSP. Convert CRSP dates to the 28th of the month for simplicity. The left join makes the missing values issues transparent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b589bed7-adcd-4492-81ee-ca1f1d1a8e2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 216)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>permno</th><th>date</th><th>ret</th><th>yyyymm_signals</th><th>AM</th><th>AOP</th><th>AbnormalAccruals</th><th>Accruals</th><th>AccrualsBM</th><th>Activism1</th><th>Activism2</th><th>AdExp</th><th>AgeIPO</th><th>AnalystRevision</th><th>AnalystValue</th><th>AnnouncementReturn</th><th>AssetGrowth</th><th>BM</th><th>BMdec</th><th>BPEBM</th><th>Beta</th><th>BetaFP</th><th>BetaLiquidityPS</th><th>BetaTailRisk</th><th>BidAskSpread</th><th>BookLeverage</th><th>BrandInvest</th><th>CBOperProf</th><th>CF</th><th>CPVolSpread</th><th>Cash</th><th>CashProd</th><th>ChAssetTurnover</th><th>ChEQ</th><th>ChForecastAccrual</th><th>ChInv</th><th>ChInvIA</th><th>&hellip;</th><th>Spinoff</th><th>SurpriseRD</th><th>Tax</th><th>TotalAccruals</th><th>TrendFactor</th><th>UpRecomm</th><th>VarCF</th><th>VolMkt</th><th>VolSD</th><th>VolumeTrend</th><th>XFIN</th><th>betaVIX</th><th>cfp</th><th>dCPVolSpread</th><th>dNoa</th><th>dVolCall</th><th>dVolPut</th><th>fgr5yrLag</th><th>grcapx</th><th>grcapx3y</th><th>hire</th><th>iomom_cust</th><th>iomom_supp</th><th>realestate</th><th>retConglomerate</th><th>roaq</th><th>sfe</th><th>sinAlgo</th><th>skew1</th><th>std_turn</th><th>tang</th><th>zerotrade12M</th><th>zerotrade1M</th><th>zerotrade6M</th><th>Price</th><th>Size</th><th>STreversal</th></tr><tr><td>i32</td><td>date</td><td>f64</td><td>i32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>&hellip;</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>10000</td><td>1986-01-28</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>10000</td><td>1986-02-28</td><td>-25.7143</td><td>198601</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.005234</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-1.475906</td><td>-2.778819</td><td>-0.0</td></tr><tr><td>10000</td><td>1986-03-28</td><td>36.5385</td><td>198602</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.003488</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>4.7852e-8</td><td>null</td><td>-1.178655</td><td>-2.481568</td><td>0.257143</td></tr><tr><td>10000</td><td>1986-04-28</td><td>-9.8592</td><td>198603</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-0.002715</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.0234e-7</td><td>null</td><td>-1.490091</td><td>-2.793004</td><td>-0.365385</td></tr><tr><td>10000</td><td>1986-05-28</td><td>-22.2656</td><td>198604</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.000877</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>7.4675e-8</td><td>null</td><td>-1.386294</td><td>-2.719452</td><td>0.098592</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 216)\n",
       "┌────────┬────────────┬──────────┬────────────┬───┬────────────┬───────────┬───────────┬───────────┐\n",
       "│ permno ┆ date       ┆ ret      ┆ yyyymm_sig ┆ … ┆ zerotrade6 ┆ Price     ┆ Size      ┆ STreversa │\n",
       "│ ---    ┆ ---        ┆ ---      ┆ nals       ┆   ┆ M          ┆ ---       ┆ ---       ┆ l         │\n",
       "│ i32    ┆ date       ┆ f64      ┆ ---        ┆   ┆ ---        ┆ f32       ┆ f32       ┆ ---       │\n",
       "│        ┆            ┆          ┆ i32        ┆   ┆ f32        ┆           ┆           ┆ f32       │\n",
       "╞════════╪════════════╪══════════╪════════════╪═══╪════════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 10000  ┆ 1986-01-28 ┆ null     ┆ null       ┆ … ┆ null       ┆ null      ┆ null      ┆ null      │\n",
       "│ 10000  ┆ 1986-02-28 ┆ -25.7143 ┆ 198601     ┆ … ┆ null       ┆ -1.475906 ┆ -2.778819 ┆ -0.0      │\n",
       "│ 10000  ┆ 1986-03-28 ┆ 36.5385  ┆ 198602     ┆ … ┆ null       ┆ -1.178655 ┆ -2.481568 ┆ 0.257143  │\n",
       "│ 10000  ┆ 1986-04-28 ┆ -9.8592  ┆ 198603     ┆ … ┆ null       ┆ -1.490091 ┆ -2.793004 ┆ -0.365385 │\n",
       "│ 10000  ┆ 1986-05-28 ┆ -22.2656 ┆ 198604     ┆ … ┆ null       ┆ -1.386294 ┆ -2.719452 ┆ 0.098592  │\n",
       "└────────┴────────────┴──────────┴────────────┴───┴────────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert crsp dates to the 28th of the month\n",
    "crsp = crsp.select(\n",
    "    pl.col(\"permno\").cast(pl.Int32),\n",
    "    pl.col(\"date\")\n",
    "    .dt.year()\n",
    "    .mul(100)\n",
    "    .add(pl.col(\"date\").dt.month())\n",
    "    .cast(pl.String)\n",
    "    .add(\"28\")\n",
    "    .str.to_date(\"%Y%m%d\"),\n",
    "    \"ret\",\n",
    ")\n",
    "\n",
    "# lLeft join returns onto signals, in-place (for ram)\n",
    "bigdat = crsp.join(bigdat, on=[\"permno\", \"date\"], how=\"left\")\n",
    "\n",
    "bigdat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a038aa-fef3-4c5d-ac5e-5c15b4cf8f42",
   "metadata": {},
   "source": [
    "Congrats, the data is merged! But unfortunately, we'll need to do a bit more work to make it usable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8def6e12-1f2e-4ac9-a942-eed0c5ed70d5",
   "metadata": {},
   "source": [
    "# Process data for ML\n",
    "We'll need to deal with the missing signals. This is a notorious issue with big data. Here, we'll just standardize the signals and then fill in missings with zero. This follows [Chen and McCoy (2024)](https://arxiv.org/abs/2207.13071)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b7b5cd5d-0ece-44b0-a4ce-002e3386c204",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy over, keep only after 1963 and non-missing returns\n",
    "cleandat = bigdat.filter(pl.col(\"date\").dt.year() >= 1963, pl.col(\"ret\").is_not_null())\n",
    "\n",
    "cleandat = (\n",
    "    cleandat\n",
    "    # Standardize\n",
    "    .with_columns(\n",
    "        (pl.col(signal_list) - pl.col(signal_list).mean()) / pl.col(signal_list).std()\n",
    "    )\n",
    "    # Replace null with 0\n",
    "    .fill_null(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef7227e",
   "metadata": {},
   "source": [
    "<span style=\"color:orange;font-weight:bold\">Optional:</span> Below, we reduce the number of signals for tractability. To use more signals, modify `nsignals_for_ml` at the beginning of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "685171c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 216)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>permno</th><th>date</th><th>ret</th><th>yyyymm_signals</th><th>AM</th><th>AOP</th><th>AbnormalAccruals</th><th>Accruals</th><th>AccrualsBM</th><th>Activism1</th><th>Activism2</th><th>AdExp</th><th>AgeIPO</th><th>AnalystRevision</th><th>AnalystValue</th><th>AnnouncementReturn</th><th>AssetGrowth</th><th>BM</th><th>BMdec</th><th>BPEBM</th><th>Beta</th><th>BetaFP</th><th>BetaLiquidityPS</th><th>BetaTailRisk</th><th>BidAskSpread</th><th>BookLeverage</th><th>BrandInvest</th><th>CBOperProf</th><th>CF</th><th>CPVolSpread</th><th>Cash</th><th>CashProd</th><th>ChAssetTurnover</th><th>ChEQ</th><th>ChForecastAccrual</th><th>ChInv</th><th>ChInvIA</th><th>&hellip;</th><th>Spinoff</th><th>SurpriseRD</th><th>Tax</th><th>TotalAccruals</th><th>TrendFactor</th><th>UpRecomm</th><th>VarCF</th><th>VolMkt</th><th>VolSD</th><th>VolumeTrend</th><th>XFIN</th><th>betaVIX</th><th>cfp</th><th>dCPVolSpread</th><th>dNoa</th><th>dVolCall</th><th>dVolPut</th><th>fgr5yrLag</th><th>grcapx</th><th>grcapx3y</th><th>hire</th><th>iomom_cust</th><th>iomom_supp</th><th>realestate</th><th>retConglomerate</th><th>roaq</th><th>sfe</th><th>sinAlgo</th><th>skew1</th><th>std_turn</th><th>tang</th><th>zerotrade12M</th><th>zerotrade1M</th><th>zerotrade6M</th><th>Price</th><th>Size</th><th>STreversal</th></tr><tr><td>i32</td><td>date</td><td>f64</td><td>i32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>&hellip;</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>10000</td><td>1986-02-28</td><td>-25.7143</td><td>198601</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>-0.160952</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.25426</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.644967</td><td>0.851256</td><td>0.059751</td></tr><tr><td>10000</td><td>1986-03-28</td><td>36.5385</td><td>198602</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>-0.160952</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.159584</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.413432</td><td>0.0</td><td>0.870564</td><td>0.979924</td><td>1.458834</td></tr><tr><td>10000</td><td>1986-04-28</td><td>-9.8592</td><td>198603</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>-0.160952</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.117701</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.413432</td><td>0.0</td><td>0.634201</td><td>0.845117</td><td>-1.928263</td></tr><tr><td>10000</td><td>1986-05-28</td><td>-22.2656</td><td>198604</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>-0.160952</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.07704</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.413432</td><td>0.0</td><td>0.712977</td><td>0.876954</td><td>0.596178</td></tr><tr><td>10000</td><td>1986-06-28</td><td>-0.5025</td><td>198605</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>-0.160952</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.507541</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.413432</td><td>0.0</td><td>0.904133</td><td>0.985979</td><td>1.271195</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 216)\n",
       "┌────────┬────────────┬──────────┬─────────────┬───┬────────────┬──────────┬──────────┬────────────┐\n",
       "│ permno ┆ date       ┆ ret      ┆ yyyymm_sign ┆ … ┆ zerotrade6 ┆ Price    ┆ Size     ┆ STreversal │\n",
       "│ ---    ┆ ---        ┆ ---      ┆ als         ┆   ┆ M          ┆ ---      ┆ ---      ┆ ---        │\n",
       "│ i32    ┆ date       ┆ f64      ┆ ---         ┆   ┆ ---        ┆ f32      ┆ f32      ┆ f32        │\n",
       "│        ┆            ┆          ┆ i32         ┆   ┆ f32        ┆          ┆          ┆            │\n",
       "╞════════╪════════════╪══════════╪═════════════╪═══╪════════════╪══════════╪══════════╪════════════╡\n",
       "│ 10000  ┆ 1986-02-28 ┆ -25.7143 ┆ 198601      ┆ … ┆ 0.0        ┆ 0.644967 ┆ 0.851256 ┆ 0.059751   │\n",
       "│ 10000  ┆ 1986-03-28 ┆ 36.5385  ┆ 198602      ┆ … ┆ 0.0        ┆ 0.870564 ┆ 0.979924 ┆ 1.458834   │\n",
       "│ 10000  ┆ 1986-04-28 ┆ -9.8592  ┆ 198603      ┆ … ┆ 0.0        ┆ 0.634201 ┆ 0.845117 ┆ -1.928263  │\n",
       "│ 10000  ┆ 1986-05-28 ┆ -22.2656 ┆ 198604      ┆ … ┆ 0.0        ┆ 0.712977 ┆ 0.876954 ┆ 0.596178   │\n",
       "│ 10000  ┆ 1986-06-28 ┆ -0.5025  ┆ 198605      ┆ … ┆ 0.0        ┆ 0.904133 ┆ 0.985979 ┆ 1.271195   │\n",
       "└────────┴────────────┴──────────┴─────────────┴───┴────────────┴──────────┴──────────┴────────────┘"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make data smaller\n",
    "nsignals_for_ml = min(len(signal_list), nsignals_for_ml)\n",
    "# Select columns from cleandat: (permno, date, ret, yyyymm_signals, [nsignals_for_ml])\n",
    "cleandat = cleandat.select(cleandat.columns[:(4 + nsignals_for_ml)])\n",
    "# Make our signal list match our selected data\n",
    "signal_list = signal_list[:nsignals_for_ml]\n",
    "\n",
    "# Show clean data with filtered/unfiltered signal list\n",
    "cleandat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dce887d-e653-40b3-8bab-376a783517fa",
   "metadata": {},
   "source": [
    "# ML-style portfolios (with OLS)\n",
    "Following Lewellen (2014, CFR), let's predict returns using many signals and then sort stocks on the predicted returns. We'll do this in perhaps the simplest way possible: fit returns with OLS using the \"groovy\" 1963-1979 sample. Then use the fitted coefficients on lagged signals to sort stocks every month from 1980 onward. \n",
    "\n",
    "This can't work, can it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "90706acc-f2fc-446c-ab9c-c89898f9ebf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# User-specified fit period\n",
    "fit_start = 1963\n",
    "fit_end = 1979\n",
    "\n",
    "# User-specified number of portfolios\n",
    "nport = 5\n",
    "\n",
    "# Make a copy of our dataframe specific to the OLS example\n",
    "cleandat_ols = cleandat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e16efca4-de8b-458f-8cc7-b086e082e458",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit returns\n",
    "formula = \"ret ~ \" + \" + \".join(signal_list)\n",
    "\n",
    "fit = smf.ols(\n",
    "    formula,\n",
    "    data=cleandat_ols.filter(\n",
    "        pl.col(\"date\").dt.year().is_between(fit_start, fit_end - 1)\n",
    "    ),\n",
    ").fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c6f7f894-38e3-4607-a0a1-f62934ed0b66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply fit to all data\n",
    "# Do it chunk by chunk to avoid large momory consumption caused by large matrix operation\n",
    "res = []\n",
    "for i in cleandat_ols.iter_slices(n_rows=len(cleandat_ols) // 100):\n",
    "    temp = i.select(pl.lit(1), pl.col(signal_list)).to_numpy() @ fit.params.values\n",
    "    res += list(temp)\n",
    "\n",
    "cleandat_ols = cleandat_ols.with_columns(pred=np.array(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2cd63567-ff24-4dff-850c-1e08f94397c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Find portfolio returns ==\n",
    "\n",
    "# Copy data\n",
    "preddat = cleandat_ols.select(\"permno\", \"date\", \"pred\", \"ret\").to_pandas()\n",
    "\n",
    "# Define port sort function\n",
    "# Follows https://github.com/chenandrewy/flex-mining/blob/70ca658090a13fea8517945280b2de83b9886968/0_Environment.R#L465\n",
    "def port_sort(x, nport):\n",
    "    return np.ceil(x.rank(method=\"min\") * nport / (len(x) + 1)).astype(int)\n",
    "\n",
    "preddat[\"port\"] = preddat.groupby(\"date\")[\"pred\"].transform(port_sort, nport=nport)\n",
    "\n",
    "# Find portfolio returns\n",
    "portdat = (\n",
    "    preddat.groupby([\"port\", \"date\"], observed=False)\n",
    "    .agg(ret=(\"ret\", \"mean\"), nstock=(\"permno\", \"nunique\"))\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a3e5e9",
   "metadata": {},
   "source": [
    "How does this portfolio do after the \"groovy\" era? Let's check how it does during the hair metal (1980s), gangsta rap (1990s), emo (2000s), EDM (2010s), and TSwift (2020s) samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "69bfc154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subsamp</th>\n",
       "      <th>datemin</th>\n",
       "      <th>datemax</th>\n",
       "      <th>port_1</th>\n",
       "      <th>port_2</th>\n",
       "      <th>port_3</th>\n",
       "      <th>port_4</th>\n",
       "      <th>port_5</th>\n",
       "      <th>5_minus_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>groovy</td>\n",
       "      <td>1963-01-28</td>\n",
       "      <td>1969-12-28</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.92</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>groovy (still)</td>\n",
       "      <td>1970-01-28</td>\n",
       "      <td>1979-12-28</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.29</td>\n",
       "      <td>4.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hair metal</td>\n",
       "      <td>1980-01-28</td>\n",
       "      <td>1989-12-28</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gangsta rap</td>\n",
       "      <td>1990-01-28</td>\n",
       "      <td>1999-12-28</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.69</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emo</td>\n",
       "      <td>2000-01-28</td>\n",
       "      <td>2009-12-28</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EDM</td>\n",
       "      <td>2010-01-28</td>\n",
       "      <td>2019-12-28</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TSwift</td>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subsamp    datemin    datemax  port_1  port_2  port_3  port_4  \\\n",
       "0          groovy 1963-01-28 1969-12-28    0.49    0.99    1.44    1.90   \n",
       "1  groovy (still) 1970-01-28 1979-12-28   -0.82    0.33    1.07    1.87   \n",
       "2      hair metal 1980-01-28 1989-12-28   -0.10    0.91    1.34    1.58   \n",
       "3     gangsta rap 1990-01-28 1999-12-28   -0.00    0.73    1.12    1.69   \n",
       "4             emo 2000-01-28 2009-12-28   -0.24    0.38    0.84    1.22   \n",
       "5             EDM 2010-01-28 2019-12-28    0.42    0.84    0.93    1.12   \n",
       "6          TSwift 2020-01-28 2023-12-28   -0.16    0.82    0.89    1.05   \n",
       "\n",
       "   port_5  5_minus_1  \n",
       "0    2.92       2.43  \n",
       "1    3.29       4.11  \n",
       "2    2.35       2.45  \n",
       "3    3.54       3.54  \n",
       "4    2.57       2.81  \n",
       "5    1.40       0.98  \n",
       "6    1.36       1.52  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find performance by 10-year periods\n",
    "samplength = 10\n",
    "\n",
    "portdat[\"subsamp\"] = pd.cut(\n",
    "    portdat[\"date\"].dt.year,\n",
    "    bins=range(1959, 2030, samplength),\n",
    "    labels=range(1959, 2029, samplength),\n",
    ")\n",
    "\n",
    "portsum = (\n",
    "    portdat.groupby([\"port\", \"subsamp\"], observed=False)\n",
    "    .agg(\n",
    "        meanret=(\"ret\", \"mean\"),\n",
    "        vol=(\"ret\", \"std\"),\n",
    "        nmonth=(\"date\", \"nunique\"),\n",
    "        nstock=(\"nstock\", \"mean\"),\n",
    "        datemin=(\"date\", \"min\"),\n",
    "        datemax=(\"date\", \"max\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "portsum[\"meanret\"] = round(portsum[\"meanret\"], 2)\n",
    "\n",
    "# Pivot meanret to wide format\n",
    "sumwide = portsum.pivot(index=\"subsamp\", columns=\"port\", values=\"meanret\").reset_index()\n",
    "sumwide.columns = [\"subsamp\"] + [f\"port_{col}\" for col in sumwide.columns[1:]]\n",
    "\n",
    "# Add long-short\n",
    "sumwide[\"5_minus_1\"] = sumwide[\"port_5\"] - sumwide[\"port_1\"]\n",
    "\n",
    "# Add date ranges\n",
    "temp = (\n",
    "    portsum.groupby(\"subsamp\", observed=False)\n",
    "    .agg(datemin=(\"datemin\", \"min\"), datemax=(\"datemax\", \"max\"))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "sumwide = pd.merge(temp, sumwide, on=\"subsamp\", how=\"left\")\n",
    "\n",
    "# Name the subsamples\n",
    "sumwide[\"subsamp\"] = sumwide[\"subsamp\"].map(\n",
    "    {\n",
    "        1959: \"groovy\",\n",
    "        1969: \"groovy (still)\",\n",
    "        1979: \"hair metal\",\n",
    "        1989: \"gangsta rap\",\n",
    "        1999: \"emo\",\n",
    "        2009: \"EDM\",\n",
    "        2019: \"TSwift\",\n",
    "    }\n",
    ")\n",
    "\n",
    "sumwide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2373b20c",
   "metadata": {},
   "source": [
    "The OLS model, fitted only using groovy era data, makes it through hair metal, gansta rap, and emo quite well. In the corresponding decades, the groovy model earns long-short returns of 2.0 to 3.0 percent per month. So a model from the [Simon and Garfunkel](https://en.wikipedia.org/wiki/Groovy#/media/File:Soundofsilence.jpg) days continued to predict quite well, even while [Metallica inexplicably started to paint their fingernails black](https://www.reddit.com/r/Metallica/comments/huk18i/never_forget_emotallica/). \n",
    "\n",
    "During EDM and the Tswift eras, the model produces some notable magnitudes, though the returns are much weaker than they were while [Ms. Swift was still into pickup trucks](https://www.youtube.com/watch?v=GkD20ajVxnY).\n",
    "\n",
    "There are huge caveats about trading costs (Chen and Velikov 2023). But then again, this tutorial doesn't even attempt to deal with trading costs. One can likely do much better by following DeMiguel, Martin-Utrera, Nogales, and Uppal (2020) or Jensen, Kelly, Malamud, and Pedersen (2024)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec2fd96",
   "metadata": {},
   "source": [
    "# ML-Portfolios with a Simple Feed-Forward Neural Network \n",
    "\n",
    "It's kind of cringey to call OLS \"machine learning\" (almost as cringey as [Emotallica](https://www.reddit.com/r/Metallica/comments/huk18i/never_forget_emotallica/)). Let's make a proper ML portfolio, using now with scikit-learn's implementation of a simple neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "241ad656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-specified parameters\n",
    "fit_start = 1963\n",
    "fit_end = 1979\n",
    "nport = 5\n",
    "\n",
    "cleandat_mlp = cleandat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bf25e382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "filtered_data = cleandat_mlp.filter(\n",
    "    pl.col(\"date\").dt.year().is_between(fit_start, fit_end - 1)\n",
    ")\n",
    "X = filtered_data.select(pl.col(signal_list)).to_pandas().values\n",
    "y = filtered_data.select(pl.col(\"ret\")).to_pandas().values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d4272c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features for neural network\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3feb14c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(alpha=0.001, batch_size=10000, early_stopping=True,\n",
       "             hidden_layer_sizes=(32, 16, 8), learning_rate_init=0.01,\n",
       "             max_iter=100, n_iter_no_change=5, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MLPRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.neural_network.MLPRegressor.html\">?<span>Documentation for MLPRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MLPRegressor(alpha=0.001, batch_size=10000, early_stopping=True,\n",
       "             hidden_layer_sizes=(32, 16, 8), learning_rate_init=0.01,\n",
       "             max_iter=100, n_iter_no_change=5, random_state=1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(alpha=0.001, batch_size=10000, early_stopping=True,\n",
       "             hidden_layer_sizes=(32, 16, 8), learning_rate_init=0.01,\n",
       "             max_iter=100, n_iter_no_change=5, random_state=1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/test split for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=1\n",
    ")\n",
    "\n",
    "# Define and train the MLPRegressor\n",
    "mlp = MLPRegressor(\n",
    "    hidden_layer_sizes=(32, 16, 8),  # Increase neurons for more learning capacity\n",
    "    activation=\"relu\",  # Good for nonlinear relationships\n",
    "    solver=\"adam\",  # Robust optimizer for noisy data\n",
    "    alpha=0.001,  # Add regularization to reduce overfitting\n",
    "    batch_size=10000,\n",
    "    learning_rate_init=0.01,  # Lower learning rate for finer optimization\n",
    "    max_iter=100,  # Allow more iterations for convergence\n",
    "    early_stopping=True,  # Stop training if validation error doesn't improve\n",
    "    n_iter_no_change=5,  # Patience for early stopping\n",
    "    random_state=1,  # Ensure reproducibility\n",
    ")\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4b5a254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the trained model to all data (chunk by chunk)\n",
    "res = []\n",
    "for i in cleandat_mlp.iter_slices(n_rows=len(cleandat_mlp) // 100):\n",
    "    temp_data = i.select(pl.col(signal_list)).to_numpy()\n",
    "    temp_data_scaled = scaler.transform(temp_data)\n",
    "    temp_mlp = mlp.predict(temp_data_scaled)\n",
    "    res.extend(temp_mlp)\n",
    "\n",
    "cleandat_mlp = cleandat_mlp.with_columns(pred=np.array(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "57316738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Find portfolio returns ==\n",
    "# Copy data\n",
    "preddat_mlp = cleandat_mlp.select(\"permno\", \"date\", \"pred\", \"ret\").to_pandas()\n",
    "\n",
    "# Define port sort function\n",
    "def port_sort(x, nport):\n",
    "    return np.ceil(x.rank(method=\"min\") * nport / (len(x) + 1)).astype(int)\n",
    "\n",
    "preddat_mlp[\"port\"] = preddat_mlp.groupby(\"date\")[\"pred\"].transform(\n",
    "    port_sort, nport=nport\n",
    ")\n",
    "\n",
    "# Find portfolio returns\n",
    "portdat_mlp = (\n",
    "    preddat_mlp.groupby([\"port\", \"date\"], observed=False)\n",
    "    .agg(ret=(\"ret\", \"mean\"), nstock=(\"permno\", \"nunique\"))\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28abfe5a",
   "metadata": {},
   "source": [
    "Okay, now that we have our portfolio, fitted to groovy data. Let's see how it works on more recent data, from hair metal to Taylor and the Chiefs guy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "99d723f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subsamp</th>\n",
       "      <th>datemin</th>\n",
       "      <th>datemax</th>\n",
       "      <th>port_1</th>\n",
       "      <th>port_2</th>\n",
       "      <th>port_3</th>\n",
       "      <th>port_4</th>\n",
       "      <th>port_5</th>\n",
       "      <th>5_minus_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>groovy</td>\n",
       "      <td>1963-01-28</td>\n",
       "      <td>1969-12-28</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.98</td>\n",
       "      <td>3.45</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>groovy (still)</td>\n",
       "      <td>1970-01-28</td>\n",
       "      <td>1979-12-28</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2.01</td>\n",
       "      <td>4.32</td>\n",
       "      <td>5.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hair metal</td>\n",
       "      <td>1980-01-28</td>\n",
       "      <td>1989-12-28</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.49</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gangsta rap</td>\n",
       "      <td>1990-01-28</td>\n",
       "      <td>1999-12-28</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.61</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emo</td>\n",
       "      <td>2000-01-28</td>\n",
       "      <td>2009-12-28</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.12</td>\n",
       "      <td>2.34</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EDM</td>\n",
       "      <td>2010-01-28</td>\n",
       "      <td>2019-12-28</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TSwift</td>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subsamp    datemin    datemax  port_1  port_2  port_3  port_4  \\\n",
       "0          groovy 1963-01-28 1969-12-28    0.03    0.94    1.35    1.98   \n",
       "1  groovy (still) 1970-01-28 1979-12-28   -1.48   -0.11    1.01    2.01   \n",
       "2      hair metal 1980-01-28 1989-12-28    0.25    0.96    1.30    1.49   \n",
       "3     gangsta rap 1990-01-28 1999-12-28    0.34    0.75    1.20    1.61   \n",
       "4             emo 2000-01-28 2009-12-28    0.03    0.44    0.83    1.12   \n",
       "5             EDM 2010-01-28 2019-12-28    0.66    0.96    0.96    1.06   \n",
       "6          TSwift 2020-01-28 2023-12-28    0.51    0.46    0.72    1.19   \n",
       "\n",
       "   port_5  5_minus_1  \n",
       "0    3.45       3.42  \n",
       "1    4.32       5.80  \n",
       "2    2.08       1.83  \n",
       "3    3.17       2.83  \n",
       "4    2.34       2.31  \n",
       "5    1.06       0.40  \n",
       "6    1.08       0.57  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find performance by 10-year periods\n",
    "samplength = 10\n",
    "\n",
    "portdat_mlp[\"subsamp\"] = pd.cut(\n",
    "    portdat_mlp[\"date\"].dt.year,\n",
    "    bins=range(1959, 2030, samplength),\n",
    "    labels=range(1959, 2029, samplength),\n",
    ")\n",
    "\n",
    "portsum_mlp = (\n",
    "    portdat_mlp.groupby([\"port\", \"subsamp\"], observed=False)\n",
    "    .agg(\n",
    "        meanret=(\"ret\", \"mean\"),\n",
    "        vol=(\"ret\", \"std\"),\n",
    "        nmonth=(\"date\", \"nunique\"),\n",
    "        nstock=(\"nstock\", \"mean\"),\n",
    "        datemin=(\"date\", \"min\"),\n",
    "        datemax=(\"date\", \"max\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "portsum_mlp[\"meanret\"] = round(portsum_mlp[\"meanret\"], 2)\n",
    "\n",
    "# Pivot meanret to wide format\n",
    "sumwide_mlp = portsum_mlp.pivot(\n",
    "    index=\"subsamp\", columns=\"port\", values=\"meanret\"\n",
    ").reset_index()\n",
    "sumwide_mlp.columns = [\"subsamp\"] + [f\"port_{col}\" for col in sumwide_mlp.columns[1:]]\n",
    "\n",
    "# Add long-short\n",
    "sumwide_mlp[\"5_minus_1\"] = sumwide_mlp[\"port_5\"] - sumwide_mlp[\"port_1\"]\n",
    "\n",
    "# Add date ranges\n",
    "temp_mlp = (\n",
    "    portsum_mlp.groupby(\"subsamp\", observed=False)\n",
    "    .agg(datemin=(\"datemin\", \"min\"), datemax=(\"datemax\", \"max\"))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "sumwide_mlp = pd.merge(temp_mlp, sumwide_mlp, on=\"subsamp\", how=\"left\")\n",
    "\n",
    "# Name the subsamples\n",
    "sumwide_mlp[\"subsamp\"] = sumwide_mlp[\"subsamp\"].map(\n",
    "    {\n",
    "        1959: \"groovy\",\n",
    "        1969: \"groovy (still)\",\n",
    "        1979: \"hair metal\",\n",
    "        1989: \"gangsta rap\",\n",
    "        1999: \"emo\",\n",
    "        2009: \"EDM\",\n",
    "        2019: \"TSwift\",\n",
    "    }\n",
    ")\n",
    "\n",
    "sumwide_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a28d6d",
   "metadata": {},
   "source": [
    "Ew. \n",
    "\n",
    "Our neural network actually performs somewhat worse than OLS. While Tommy and Gina were [Livin on a Prayer](https://www.youtube.com/watch?v=lDK9QqIzhwk), or Snoop was [sippin on Gin and Juice](https://www.youtube.com/watch?v=fWCZse1iwE0), the neural network earns about 20% less than OLS. \n",
    "\n",
    "This might be because we're not following the best practices from the literature. You can't just fit a model on some hippie stuff and expect to work after Reagan takes office. \n",
    "\n",
    "The best practice is to refit frequently, to ensure that the model is up-to-date (e.g. [Gu, Kelly, Xiu 2020](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3159577)). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c296da8",
   "metadata": {},
   "source": [
    "# Neural Network With Refitting\n",
    "Let's use expanding windows with 2 years in between each refitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "83f20f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subsamp</th>\n",
       "      <th>datemin</th>\n",
       "      <th>datemax</th>\n",
       "      <th>port_1</th>\n",
       "      <th>port_2</th>\n",
       "      <th>port_3</th>\n",
       "      <th>port_4</th>\n",
       "      <th>port_5</th>\n",
       "      <th>5_minus_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hair metal</td>\n",
       "      <td>1980-01-28</td>\n",
       "      <td>1989-12-28</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.79</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gangsta rap</td>\n",
       "      <td>1990-01-28</td>\n",
       "      <td>1999-12-28</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.26</td>\n",
       "      <td>2.06</td>\n",
       "      <td>4.21</td>\n",
       "      <td>5.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emo</td>\n",
       "      <td>2000-01-28</td>\n",
       "      <td>2009-12-28</td>\n",
       "      <td>-1.21</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.59</td>\n",
       "      <td>3.13</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EDM</td>\n",
       "      <td>2010-01-28</td>\n",
       "      <td>2019-12-28</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.97</td>\n",
       "      <td>2.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TSwift</td>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.98</td>\n",
       "      <td>2.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       subsamp    datemin    datemax  port_1  port_2  port_3  port_4  port_5  \\\n",
       "2   hair metal 1980-01-28 1989-12-28   -0.34    0.77    1.35    1.79    2.51   \n",
       "3  gangsta rap 1990-01-28 1999-12-28   -0.94    0.51    1.26    2.06    4.21   \n",
       "4          emo 2000-01-28 2009-12-28   -1.21    0.23    1.08    1.59    3.13   \n",
       "5          EDM 2010-01-28 2019-12-28   -0.11    0.88    1.01    1.23    1.97   \n",
       "6       TSwift 2020-01-28 2023-12-28   -0.57    0.69    0.81    1.30    1.98   \n",
       "\n",
       "   5_minus_1  \n",
       "2       2.85  \n",
       "3       5.15  \n",
       "4       4.34  \n",
       "5       2.08  \n",
       "6       2.55  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters for expanding window estimation\n",
    "cleandat_refit = cleandat  # Copy of clean data\n",
    "refit_period = 2 # Number of years between model refits\n",
    "fit_start = 1963  # Initial training start year\n",
    "fit_end = 1979  # Initial training end year\n",
    "nport = 5  # Number of portfolios to form\n",
    "\n",
    "# Lists to store results\n",
    "all_predictions = []  # Store all model predictions\n",
    "all_portdat = []  # Store all portfolio returns\n",
    "\n",
    "# Rolling window estimation\n",
    "for end_year in range(fit_end, 2030, refit_period):\n",
    "    # Get training data between 1963-1979\n",
    "    train_data = cleandat_refit.filter(\n",
    "        pl.col(\"date\").dt.year().is_between(fit_start, end_year)\n",
    "    )\n",
    "    X_train = train_data.select(pl.col(signal_list)).to_pandas().values\n",
    "    y_train = train_data.select(pl.col(\"ret\")).to_pandas().values.ravel()\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "    # Initialize and train neural network\n",
    "    mlp = MLPRegressor(\n",
    "        hidden_layer_sizes=(32, 16, 8),\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        alpha=0.0001,\n",
    "        batch_size=10000,\n",
    "        learning_rate_init=0.01,\n",
    "        max_iter=100,\n",
    "        early_stopping=True,\n",
    "        n_iter_no_change=5,\n",
    "        random_state=end_year,\n",
    "    )\n",
    "    mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Get test data for next period\n",
    "    test_data = cleandat_refit.filter(\n",
    "        pl.col(\"date\").dt.year().is_between(end_year + 1, end_year + refit_period)\n",
    "    )\n",
    "    if len(test_data) == 0:\n",
    "        continue\n",
    "\n",
    "    # Generate predictions on test data\n",
    "    X_test = test_data.select(pl.col(signal_list)).to_pandas().values\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    predictions = mlp.predict(X_test_scaled)\n",
    "\n",
    "    # Add predictions to test data\n",
    "    test_data = test_data.with_columns(pred=predictions).select(\n",
    "        [\"permno\", \"date\", \"pred\", \"ret\"]\n",
    "    )\n",
    "    all_predictions.append(test_data)\n",
    "\n",
    "    # Form portfolios based on predictions\n",
    "    preddat_refit = test_data.to_pandas()\n",
    "    preddat_refit[\"port\"] = preddat_refit.groupby(\"date\")[\"pred\"].transform(\n",
    "        port_sort, nport=nport\n",
    "    )\n",
    "\n",
    "    # Calculate portfolio returns\n",
    "    portdat_refit = (\n",
    "        preddat_refit.groupby([\"port\", \"date\"], observed=False)\n",
    "        .agg(ret=(\"ret\", \"mean\"), nstock=(\"permno\", \"nunique\"))\n",
    "        .reset_index()\n",
    "    )\n",
    "    all_portdat.append(portdat_refit)\n",
    "\n",
    "# Combine results\n",
    "all_predictions = pl.concat(all_predictions).select([\"permno\", \"date\", \"pred\", \"ret\"])\n",
    "portdat_refit = pd.concat(all_portdat, ignore_index=True)\n",
    "\n",
    "# Create subsamples for analysis\n",
    "samplength = 10\n",
    "\n",
    "portdat_refit[\"subsamp\"] = pd.cut(\n",
    "    portdat_refit[\"date\"].dt.year,\n",
    "    bins=range(1959, 2030, samplength),\n",
    "    labels=range(1959, 2029, samplength),\n",
    ")\n",
    "\n",
    "# Calculate summary statistics by portfolio and subsample\n",
    "portsum_refit = (\n",
    "    portdat_refit.groupby([\"port\", \"subsamp\"], observed=False)\n",
    "    .agg(\n",
    "        meanret=(\"ret\", \"mean\"),\n",
    "        vol=(\"ret\", \"std\"),\n",
    "        nmonth=(\"date\", \"nunique\"),\n",
    "        nstock=(\"nstock\", \"mean\"),\n",
    "        datemin=(\"date\", \"min\"),\n",
    "        datemax=(\"date\", \"max\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "portsum_refit[\"meanret\"] = round(portsum_refit[\"meanret\"], 2)\n",
    "\n",
    "# Pivot results to wide format\n",
    "sumwide_refit = portsum_refit.pivot(\n",
    "    index=\"subsamp\", columns=\"port\", values=\"meanret\"\n",
    ").reset_index()\n",
    "sumwide_refit.columns = [\"subsamp\"] + [\n",
    "    f\"port_{col}\" for col in sumwide_refit.columns[1:]\n",
    "]\n",
    "\n",
    "# Calculate long-short portfolio returns\n",
    "sumwide_refit[\"5_minus_1\"] = sumwide_refit[\"port_5\"] - sumwide_refit[\"port_1\"]\n",
    "\n",
    "# Add date range for each subsample\n",
    "temp_refit = (\n",
    "    portsum_refit.groupby(\"subsamp\", observed=False)\n",
    "    .agg(datemin=(\"datemin\", \"min\"), datemax=(\"datemax\", \"max\"))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "sumwide_refit = pd.merge(temp_refit, sumwide_refit, on=\"subsamp\", how=\"left\")\n",
    "\n",
    "# Add the labels for each decade\n",
    "sumwide_refit[\"subsamp\"] = sumwide_refit[\"subsamp\"].map(\n",
    "    {\n",
    "        1959: \"groovy\",\n",
    "        1969: \"groovy (still)\",\n",
    "        1979: \"hair metal\",\n",
    "        1989: \"gangsta rap\",\n",
    "        1999: \"emo\",\n",
    "        2009: \"EDM\",\n",
    "        2019: \"TSwift\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Drop first two rows (groovy & groovy (still))\n",
    "# This is because we are refitting with expanding windows so predictions do not exis for the test data \n",
    "sumwide_refit = sumwide_refit.dropna()\n",
    "\n",
    "sumwide_refit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9884554",
   "metadata": {},
   "source": [
    "Ah, that's more like it. Refitting every 2 years, the neural network consistently outperforms OLS, with returns similar to those from [Gu, Kelly, Xiu (2020)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3159577) and [Chen and McCoy (2024)](https://arxiv.org/abs/2207.13071). \n",
    "\n",
    "You kinda wish it was better than this. I mean, neural networks are supposed to solve general intelligence and everything. But if you read between the lines in the literature, you might see some other results that resemble these.\n",
    "\n",
    "Still, it's instructive to understand how important refitting is. It's natural to think the stock market predictability is not stable (e.g. McLean-Pontiff 2016; Chen-Velikov 2023). So you need to keep updating the model, to avoid using stale information. This helps explain why the groovy model fails to perform in the emo period. \n",
    "\n",
    "But why Metallica started to paint their fingernails black... ...remains a mystery."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
